<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Gen-Drive: Enhanced Diffusion Generative Driving Policy">
  <meta name="keywords" content="Autonomous Driving, Diffusion Policy, Reward Learning, Reinforcement Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Gen-Drive: Generative Driving Policy</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/robot.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/MCZhi/DTPP">
            DTPP
          </a>
          <a class="navbar-item" href="https://mczhi.github.io/GameFormer">
            GameFormer
          </a>
          <a class="navbar-item" href="https://mczhi.github.io/DIPP">
            DIPP
          </a>
          <a class="navbar-item" href="https://sites.google.com/view/versatile-behavior-diffusion">
            VBD
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Gen-Drive: Enhancing Diffusion Generative Driving Policy with Reward Modeling and Reinforcement Learning Fine-tuning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://mczhi.github.io">Zhiyu Huang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://research.nvidia.com/person/xinshuo-weng">Xinshuo Weng</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://maximilianigl.com/">Maximilian Igl</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://research.nvidia.com/person/yuxiao-chen">Yuxiao Chen</a><sup>2</sup>,
            </span>
            
            <span class="author-block">
              <a href="https://kikacaty.github.io/">Yulong Cao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.borisivanovic.com/">Boris Ivanovic</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://research.nvidia.com/person/marco-pavone">Marco Pavone</a><sup>2,3</sup>
            </span>
            <span class="author-block">
              <a href="https://lvchen.wixsite.com/automan">Chen Lyu</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Nanyang Technological University</span>
            <span class="author-block"><sup>2</sup>NVIDIA Research</span>
            <span class="author-block"><sup>3</sup>Stanford University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mczhi/gen-drive"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Comming Soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/GenDrive.png" alt="Gen-Drive Introduction" style="width: 100%;">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Gen-Drive</span> represents a paradigm shift from conventional prediction-planning approaches to a generation-evaluation framework.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The task of autonomous driving requires a deep understanding of traffic scenarios and the ability to reason about future interactions between traffic agents. 
            This paper introduces the <span class="dnerf">Gen-Drive</span> framework, which shifts from the traditional prediction-planning method to a generation-evaluation paradigm. 
          <p>
            The framework employs a behavior diffusion model as a scene generator to produce diverse possible future scenarios, 
            thereby enhancing the capability for joint interaction reasoning. 
            To facilitate decision-making, we propose a scene evaluator (reward) model, trained with pairwise preference data collected through VLM assistance. 
            Furthermore, we utilize an RL fine-tuning framework to improve the generation quality of the diffusion model, rendering it more effective for planning tasks.
          </p>
          <p>
            We conduct closed-loop planning tests on the nuPlan dataset, 
            and the results demonstrate that employing a multi-sample generation and evaluation strategy outperforms other learning-based approaches as well as the single-sample planning method. 
            Additionally, the fine-tuned generative driving policy shows significant enhancements in planning performance. 
            We further demonstrate that utilizing our learned model for evaluation or RL fine-tuning leads to better planning performance compared to those methods relying on human-designed rewards. 
          </p>
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video.  -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  <!-- </div>   -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- System Pipeline. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Model Structure</h2>
        <div class="content has-text-justified">
          <img src="./static/images/GenDriveModel.png" alt="Neural Network Structure of the Gen-Drive Model" style="width: 100%;">
          <!-- <p><i>Closed-loop process for ThinkGrasp.</i></p> -->
          <p>
            The query-centric encoding Transformer encodes all scene elements in local coordinates while preserving relative information in attention calculations.
          </p>
          <p>
            The diffusion denoise Transformer comprises multiple attention blocks that iteratively attend to noised object futures, future-scene, and ego-route interactions.
          </p>
          <p>
            During diffusion generation,  different scenes can be produced in parallel and then be fed into the scene evaluation Transformer.
          </p>
          <p>
            The evaluation model utilizes a Transformer encoder-decoder to fuse information from the future scene and map, and two MLP heads are used to reconstruct the ego plan and output a score for the scene/plan.
        </div>
      </div>
    </div>
  </div>
</section>
  

<section class="section" id="Results">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Closed-loop Planning Results</h2>
      </div>
    </div>

    <!-- First row -->
    <div class="columns is-centered">  
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">Single-Sample Planning</h3>
          <p>
            The single-sample planning method is a traditional prediction-planning approach that generates a single future scene and evaluates it with a human-designed reward.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/single/traversing_pickup_dropoff_Gen-Drive Planner_a5189e52ecf55b73.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column has-text-centered">
        <h3 class="title is-4">Multi-Sample and Scoring</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/multi/traversing_pickup_dropoff_Gen-Drive Planner_a5189e52ecf55b73.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <!-- Second row -->
    <div class="columns is-centered">  
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">Single-Sample Planning</h3>
          <p>
            Planning method B is an alternative approach to decision-making in autonomous systems.
          </p>
          <video id="video1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/single/waiting_for_pedestrian_to_cross_Gen-Drive Planner_f7da2c3fd6f05e84.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column has-text-centered">
        <h3 class="title is-4">Multi-Sample and Scoring</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Rendering technique A enhances visual realism by applying adaptive shading and lighting methods.
            </p>
            <video id="rendering-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/multi/waiting_for_pedestrian_to_cross_Gen-Drive Planner_f7da2c3fd6f05e84.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <!-- Third row -->
    <div class="columns is-centered">  
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">Before Fine-tuning</h3>
          <p>
            The multi-sample planning method generates several future scenes and evaluates them using a deep learning model for reward estimation.
          </p>
          <video id="multisample" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/multi/high_lateral_acceleration_Gen-Drive Planner_41d071d979345e7d.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column has-text-centered">
        <h3 class="title is-4">After Fine-tuning</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Dynamic scene prediction focuses on modeling interactions between multiple moving objects for more accurate predictions.
            </p>
            <video id="dynamic-scene" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/tuned/high_lateral_acceleration_Gen-Drive Planner_41d071d979345e7d.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <!-- Fourth row -->
    <div class="columns is-centered">  
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">Before Fine-tuning</h3>
          <p>
            The path planning optimization approach minimizes path costs by considering a wide range of environmental factors and obstacles.
          </p>
          <video id="path-planning" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/multi/high_lateral_acceleration_Gen-Drive Planner_875e1631b9095dc9.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column has-text-centered">
        <h3 class="title is-4">After Fine-tuning</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Advanced object detection identifies and tracks dynamic objects in real-time, enhancing safety and responsiveness in autonomous systems.
            </p>
            <video id="object-detection" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/tuned/high_lateral_acceleration_Gen-Drive Planner_875e1631b9095dc9.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <!-- Fifth row -->
    <div class="columns is-centered">  
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">Before Fine-tuning</h3>
          <p>
            Trajectory planning involves generating optimal paths for vehicles based on real-time sensor data.
          </p>
          <video id="trajectory-planning" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/single/high_lateral_acceleration_Gen-Drive Planner_d9ec238b65cb5bda.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column has-text-centered">
        <h3 class="title is-4">After Fine-tuning</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              This system predicts potential collisions and adjusts the vehicle's path to avoid any imminent dangers.
            </p>
            <video id="collision-avoidance" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/tuned/high_lateral_acceleration_Gen-Drive Planner_d9ec238b65cb5bda.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <!-- Sixth row -->
    <div class="columns is-centered">  
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">PDM-Closed Planner</h3>
          <p>
            AI-based control systems enable real-time decision-making and path adjustments based on changing environmental data and obstacles.
          </p>
          <video id="ai-control" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pdm/waiting_for_pedestrian_to_cross_PDMClosedPlanner_4064de4004385810.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column has-text-centered">
        <h3 class="title is-4">Gen-Drive Planner</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Vision-based navigation uses camera inputs to guide the vehicle, recognizing road signs, pedestrians, and other elements in real-time.
            </p>
            <video id="vision-navigation" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/multi/waiting_for_pedestrian_to_cross_Gen-Drive Planner_4064de4004385810.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <!-- Seventh row -->
    <div class="columns is-centered">  
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">PDM-Closed Planner</h3>
          <p>
            AI-based control systems enable real-time decision-making and path adjustments based on changing environmental data and obstacles.
          </p>
          <video id="ai-control" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pdm/changing_lane_PDMClosedPlanner_1d68dfeb693b526b.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column has-text-centered">
        <h3 class="title is-4">Gen-Drive Planner</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Vision-based navigation uses camera inputs to guide the vehicle, recognizing road signs, pedestrians, and other elements in real-time.
            </p>
            <video id="vision-navigation" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/tuned/changing_lane_Gen-Drive Planner_1d68dfeb693b526b.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <!-- Eighth row -->
    <div class="columns is-centered">  
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">PDM-Closed Planner</h3>
          <p>
            AI-based control systems enable real-time decision-making and path adjustments based on changing environmental data and obstacles.
          </p>
          <video id="ai-control" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pdm/traversing_pickup_dropoff_PDMClosedPlanner_f6804d2da7c7505a.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column has-text-centered">
        <h3 class="title is-4">Gen-Drive Planner</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Vision-based navigation uses camera inputs to guide the vehicle, recognizing road signs, pedestrians, and other elements in real-time.
            </p>
            <video id="vision-navigation" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/multi/traversing_pickup_dropoff_Gen-Drive Planner_a29c93d75770583a.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
